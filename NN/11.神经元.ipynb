{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 神经元\n",
    "生物学家在 20 世纪初就发现了生物神经元的结构．一个生物神经元通常具有多个树突和一条轴突．树突用来接收信息，轴突用来发送信息．当神经元所获得的输入信号的积累超过某个阈值时，它就处于兴奋状态，产生电脉冲．轴突尾端有许多末梢可以给其他神经元的树突产生连接（突触），并将电脉冲信号传递给其他神经元．\n",
    "\n",
    "![Neurons](../images/Neurons.png)\n",
    "\n",
    "### 神经网络\n",
    "一个生物神经细胞的功能比较简单，而人工神经元只是生物神经细胞的理想化和简单实现，功能更加简单．要想模拟人脑的能力，单一的神经元是远远不够的，需要通过很多神经元一起协作来完成复杂的功能．这样通过一定的连接方式或信息传递方式进行协作的神经元可以看作一个网络，就是神经网络．\n",
    "\n",
    "![NeuralNetwork](../images/NeuralNetwork.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. 前馈网络\n",
    "\n",
    "> 最简单、最直来直去的神经网络。\n",
    "\n",
    "+ 信息就像水流，从输入开始，一层一层地往前流，到输出为止。\n",
    "\n",
    "+ 中间可能有很多隐藏层（每层都有很多“神经元”），但没有回头路，不会反馈回去。\n",
    "\n",
    "+ 常用于最基础的分类、回归问题，比如：手写数字识别。\n",
    "\n",
    "#### 2. 记忆网络\n",
    "\n",
    "> 能记住过去信息的神经网络。\n",
    "\n",
    "+ 前馈神经网络只看当前输入，而记忆神经网络不仅看当前输入，还记得之前发生了什么。\n",
    "\n",
    "+ 适合处理序列数据，比如文字、语音、视频帧等。\n",
    "\n",
    "+ 最经典的是 RNN（循环神经网络），但 RNN容易遗忘，所以又出现了改良版 LSTM、GRU —— 这些有更复杂的结构来记得长久的信息。\n",
    "\n",
    "#### 3. 图网络\n",
    "\n",
    "> 专门处理“关系”的神经网络。\n",
    "\n",
    "+ 前馈网络处理的是“表格型数据”（每个样本都是独立的），\n",
    "\n",
    "+ 图网络处理的是节点之间有关系的数据，比如社交网络、分子结构、交通网络。\n",
    "\n",
    "+ 每个节点可以和其他节点有连接（边），GNN会根据邻居节点的信息来更新自己的状态。\n",
    "\n",
    "好的！我用比较通俗的方式来讲讲：\n",
    "\n",
    "---\n",
    "\n",
    "![3NN](../images/3NN.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 简单总结一张表格：\n",
    "\n",
    "| 网络类型   | 特点        | 适合什么任务         | 比喻      |\n",
    "|:-------|:----------|:---------------|:--------|\n",
    "| 前馈神经网络 | 信息只向前流动   | 分类、回归          | 水管      |\n",
    "| 记忆神经网络 | 能记住历史输入   | 序列处理（文本、语音）    | 有记忆的听众  |\n",
    "| 图神经网络  | 处理节点和边的关系 | 网络结构数据（社交网、分子） | 谈恋爱的朋友圈 |\n"
   ],
   "id": "18c1ae99a9f3957d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T15:13:02.634030Z",
     "start_time": "2025-04-29T15:13:02.548536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义激活函数：sigmoid\n",
    "def sigmoid(_x):\n",
    "    return 1 / (1 + np.exp(-_x))\n",
    "\n",
    "# 定义神经元\n",
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        # 随机初始化权重和偏置\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "    def forward(self, _x):\n",
    "        # 线性组合\n",
    "        z = np.dot(self.weights, _x) + self.bias\n",
    "        # 激活\n",
    "        return sigmoid(z)\n",
    "\n",
    "# 测试这个神经元\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)  # 固定随机种子，保证每次运行一样\n",
    "\n",
    "    neuron = Neuron(input_size=2)  # 创建一个有2个输入的神经元\n",
    "\n",
    "    x = np.array([0.5, -0.2])  # 输入样本\n",
    "    output = neuron.forward(x)\n",
    "\n",
    "    print(\"输入:\", x)\n",
    "    print(\"权重:\", neuron.weights)\n",
    "    print(\"偏置:\", neuron.bias)\n",
    "    print(\"输出:\", output)\n"
   ],
   "id": "b02a64b7cbfc59e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: [ 0.5 -0.2]\n",
      "权重: [ 0.49671415 -0.1382643 ]\n",
      "偏置: 0.6476885381006925\n",
      "输出: 0.7157950957102797\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T09:57:56.396239Z",
     "start_time": "2025-04-30T09:57:56.390242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个只有一个神经元的模型\n",
    "class SingleNeuronNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleNeuronNet, self).__init__()\n",
    "        self.neuron = nn.Linear(in_features=1, out_features=1)  # 单输入单输出 = 单神经元\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.neuron(x)\n"
   ],
   "id": "f7165ef2c76fb944",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T09:59:49.374888Z",
     "start_time": "2025-04-30T09:59:49.327043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# 实例化模型\n",
    "model = SingleNeuronNet()\n",
    "\n",
    "# 创建一个示例输入张量（batch size = 1, 输入特征数 = 1）\n",
    "example_input = torch.randn(1, 1)\n",
    "\n",
    "# 导出为 ONNX 文件\n",
    "torch.onnx.export(\n",
    "    model,                       # 要导出的模型\n",
    "    example_input,               # 示例输入\n",
    "    \"single_neuron.onnx\",        # 导出的文件名\n",
    "    input_names=[\"input\"],       # 输入张量名称\n",
    "    output_names=[\"output\"],     # 输出张量名称\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},  # 动态 batch size\n",
    "    opset_version=11             # ONNX opset 版本\n",
    ")\n",
    "\n",
    "print(\"模型已导出为 single_neuron.onnx\")\n"
   ],
   "id": "9ba233e9184ab753",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已导出为 single_neuron.onnx\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
